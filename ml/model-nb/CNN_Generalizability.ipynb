{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5423530",
   "metadata": {},
   "source": [
    "### Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3351d211",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74edf73a",
   "metadata": {},
   "source": [
    "To develop a generalizable architecture for fault diagnosis, we utilize two benchmark datasets: **KAIST** and **CWRU**.\n",
    "\n",
    "- **KAIST Dataset:** The Korea Advanced Institute of Science & Technology (KAIST) dataset contains vibration signals from rotating machinery under various fault types, motor loads, and fault severities. It provides a diverse set of conditions, making it suitable for robust model training and evaluation.\n",
    "\n",
    "- **CWRU Dataset:** The Case Western Reserve University (CWRU) bearing dataset is widely used for bearing fault diagnosis research. It includes vibration data collected under different fault types, locations, and loads.\n",
    "\n",
    "By training the ML model on both KAIST and CWRU datasets, we aim to demonstrate its ability to generalize across different machines, fault types, and operating conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986ec0e2",
   "metadata": {},
   "source": [
    "## KAIST Dataset\n",
    "The KAIST Dataset (Jung2022) has 4 sensed variables: acoustic, current, temperature, and vibration. In this case, only vibration will be used.\n",
    "- **Machine Conditions (Normal, BPFI, BPFO, Misalign, and Unbalance):** Fault types and normal operating condition\n",
    "- **Motor load (0Nm, 2Nm, 4Nm):** Torque applied to the motor simulating load\n",
    "- **Fault Severity:** Depending on the type of fault there are at least 3 severities. For example BPFI has a fault severity represented in the crack width (0.3mm, 1mm, 3mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "298b8928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading domain 0Nm...\n",
      "  Loading 0Nm_Normal from .mat file...\n",
      "  Saving 0Nm_Normal to CSV...\n",
      "  Loading 0Nm_BPFI_03 from .mat file...\n",
      "  Saving 0Nm_BPFI_03 to CSV...\n",
      "  Loading 0Nm_BPFO_03 from .mat file...\n",
      "  Saving 0Nm_BPFO_03 to CSV...\n",
      "  Loading 0Nm_Misalign_01 from .mat file...\n",
      "  Saving 0Nm_Misalign_01 to CSV...\n",
      "  Loading 0Nm_Unbalance_0583mg from .mat file...\n",
      "  Saving 0Nm_Unbalance_0583mg to CSV...\n",
      "Domain 0Nm loaded: 5 classes\n",
      "Loading domain 2Nm...\n",
      "  Loading 2Nm_Normal from .mat file...\n",
      "  Saving 2Nm_Normal to CSV...\n",
      "  Loading 2Nm_BPFI_03 from .mat file...\n",
      "  Saving 2Nm_BPFI_03 to CSV...\n",
      "  Loading 2Nm_BPFO_03 from .mat file...\n",
      "  Saving 2Nm_BPFO_03 to CSV...\n",
      "  Loading 2Nm_Misalign_01 from .mat file...\n",
      "  Saving 2Nm_Misalign_01 to CSV...\n",
      "  Loading 2Nm_Unbalance_0583mg from .mat file...\n",
      "  Saving 2Nm_Unbalance_0583mg to CSV...\n",
      "Domain 2Nm loaded: 5 classes\n",
      "Loading domain 4Nm...\n",
      "  Loading 4Nm_Normal from .mat file...\n",
      "  Saving 4Nm_Normal to CSV...\n",
      "  Loading 4Nm_BPFI_03 from .mat file...\n",
      "  Saving 4Nm_BPFI_03 to CSV...\n",
      "  Loading 4Nm_BPFO_03 from .mat file...\n",
      "  Saving 4Nm_BPFO_03 to CSV...\n",
      "  Loading 4Nm_Misalign_01 from .mat file...\n",
      "  Saving 4Nm_Misalign_01 to CSV...\n",
      "  Loading 4Nm_Unbalance_0583mg from .mat file...\n",
      "  Saving 4Nm_Unbalance_0583mg to CSV...\n",
      "Domain 4Nm loaded: 5 classes\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------ KAIST Dataset ------------------------------\n",
    "# Paths and parameters\n",
    "vibration_mat_folder_kaist = '../../data/raw_kaist/vibration_mat_25.6kHz'\n",
    "v_length_kaist = 1536000  # length of the smaller vector in the dataset\n",
    "sampling_rate_kaist = 25600  # fixed at 25.6 kHz\n",
    "\n",
    "# Class labels for different domains\n",
    "class_labels_kaist0 = ['0Nm_Normal', '0Nm_BPFI_03', '0Nm_BPFO_03', '0Nm_Misalign_01', '0Nm_Unbalance_0583mg']\n",
    "class_labels_kaist1 = ['2Nm_Normal', '2Nm_BPFI_03', '2Nm_BPFO_03', '2Nm_Misalign_01', '2Nm_Unbalance_0583mg']\n",
    "class_labels_kaist2 = ['4Nm_Normal', '4Nm_BPFI_03', '4Nm_BPFO_03', '4Nm_Misalign_01', '4Nm_Unbalance_0583mg']\n",
    "\n",
    "def load_domain_data_kaist(class_labels, domain_name):\n",
    "    \"\"\"Load vibration data for a domain, using CSV cache if available.\"\"\"\n",
    "    vibration_data = {}\n",
    "\n",
    "    folder_path = f'../../data/flex-data/kaist_csv/vibration{sampling_rate_kaist/1000}kHz_domain{domain_name}'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    print(f\"Loading domain {domain_name}...\")\n",
    "\n",
    "    for label in class_labels:\n",
    "        csv_path = f'{folder_path}/{label}.csv'\n",
    "        mat_path = os.path.join(vibration_mat_folder_kaist, f\"{label}.mat\")\n",
    "\n",
    "        # Try CSV first, fall back to .mat\n",
    "        if os.path.exists(csv_path):\n",
    "            print(f\"  Loading {label} from CSV...\")\n",
    "            vibration_data[label] = pd.read_csv(csv_path).values\n",
    "        elif os.path.exists(mat_path):\n",
    "            print(f\"  Loading {label} from .mat file...\")\n",
    "            mat_data = sio.loadmat(mat_path)\n",
    "            vibration = mat_data['Signal']['y_values'][0][0][0][0][0][:v_length_kaist, :]\n",
    "            vibration_data[label] = vibration\n",
    "\n",
    "            # Save to CSV for next time\n",
    "            print(f\"  Saving {label} to CSV...\")\n",
    "            pd.DataFrame(vibration_data[label]).to_csv(csv_path, index=False)\n",
    "        else:\n",
    "            print(f\"  Warning: {label} not found\")\n",
    "\n",
    "    print(f\"Domain {domain_name} loaded: {len(vibration_data)} classes\")\n",
    "    return vibration_data\n",
    "\n",
    "# Load all domains\n",
    "vibration_data_kaist0 = load_domain_data_kaist(class_labels_kaist0, '0Nm')\n",
    "vibration_data_kaist1 = load_domain_data_kaist(class_labels_kaist1, '2Nm')\n",
    "vibration_data_kaist2 = load_domain_data_kaist(class_labels_kaist2, '4Nm')\n",
    "\n",
    "vibration_data_kaist = {**vibration_data_kaist0, **vibration_data_kaist1, **vibration_data_kaist2}\n",
    "class_labels_kaist = list(vibration_data_kaist.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee3d264",
   "metadata": {},
   "source": [
    "## CWRU Dataset\n",
    "The Case Western Reserve University (CWRU) Bearing Dataset provides vibration measurements collected from a motor test rig with seeded bearing faults. Acceleration data was captured near the motor bearings under varying load and fault conditions.\n",
    "\n",
    "- **Machine Conditions (Normal, Inner Race, Outer Race, and Ball Faults):** Single-point faults were introduced using electro-discharge machining (EDM) at the inner race, outer race, or rolling element. Normal operating condition data is also included.  \n",
    "- **Motor Load (0–3 hp):** Torque loads applied to the 2 hp Reliance Electric motor, corresponding to operating speeds between 1720 and 1797 RPM.  \n",
    "- **Fault Severity:** Fault diameters of 0.007, 0.014, 0.021, 0.028, and 0.040 inches were tested. SKF bearings were used for smaller faults (7–21 mils) and NTN bearings for larger faults (28–40 mils).  \n",
    "- **Sensor Setup:** Vibration was recorded using accelerometers placed at the 12 o’clock position of the drive end and fan end bearings. Additional measurements were taken at the base plate in some experiments.  \n",
    "- **Sampling Rate:** Signals were collected at 12 kHz for most cases, with 48 kHz recordings available for drive end bearing faults.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52374a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading domain 0HP at 25600 Hz...\n",
      "  Loading B007_0 from .mat file and resampling...\n",
      "  Saving B007_0 resampled CSV...\n",
      "  Loading IR007_0 from .mat file and resampling...\n",
      "  Saving IR007_0 resampled CSV...\n",
      "  Loading Normal_0 from .mat file and resampling...\n",
      "  Saving Normal_0 resampled CSV...\n",
      "  Loading OR007@3_0 from .mat file and resampling...\n",
      "  Saving OR007@3_0 resampled CSV...\n",
      "  Loading OR007@6_0 from .mat file and resampling...\n",
      "  Saving OR007@6_0 resampled CSV...\n",
      "  Loading OR007@12_0 from .mat file and resampling...\n",
      "  Saving OR007@12_0 resampled CSV...\n",
      "Domain 0HP loaded: 6 classes at 25600 Hz\n",
      "Loading domain 1HP at 25600 Hz...\n",
      "  Loading B007_1 from .mat file and resampling...\n",
      "  Saving B007_1 resampled CSV...\n",
      "  Loading IR007_1 from .mat file and resampling...\n",
      "  Saving IR007_1 resampled CSV...\n",
      "  Loading Normal_1 from .mat file and resampling...\n",
      "  Saving Normal_1 resampled CSV...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from scipy.signal import resample_poly\n",
    "\n",
    "# ------------------------------ CWRU Dataset ------------------------------\n",
    "# Paths and parameters\n",
    "# Keep your original folder. The code will resample whatever it loads.\n",
    "vibration_mat_folder_cwru = '../../data/raw_cwru/vibration_mat_12kHz'  # or .../vibration_mat_12kHz if that is your source\n",
    "v_length_cwru = 1536000  # length to trim before resampling if needed\n",
    "sampling_rate_cwru = 12000\n",
    "target_sampling_rate_cwru = 25600  # target sampling rate for resampling\n",
    "\n",
    "# Integer ratio for exact 12 kHz -> 25.6 kHz conversion\n",
    "UPSAMPLE = 32\n",
    "DOWNSAMPLE = 15\n",
    "assert abs(target_sampling_rate_cwru * DOWNSAMPLE - sampling_rate_cwru * UPSAMPLE) == 0, \"Sampling rates must match 32 over 15 ratio\"\n",
    "\n",
    "# Class labels for different domains\n",
    "class_labels_cwru0 = ['B007_0', 'IR007_0', 'Normal_0', 'OR007@3_0', 'OR007@6_0', 'OR007@12_0']\n",
    "class_labels_cwru1 = ['B007_1', 'IR007_1', 'Normal_1', 'OR007@3_1', 'OR007@6_1', 'OR007@12_1']\n",
    "class_labels_cwru2 = ['B007_2', 'IR007_2', 'Normal_2', 'OR007@3_2', 'OR007@6_2', 'OR007@12_2']\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "def _load_mat_signal(mat_path, max_len=None, channels=(\"DE\", \"FE\", \"BA\")):\n",
    "    \"\"\"\n",
    "    Load CWRU vibration from .mat and return a 2D array [time, channels].\n",
    "    Channels are taken in order DE, FE, BA if present.\n",
    "    Ignores the *RPM scalar.\n",
    "    \"\"\"\n",
    "    m = sio.loadmat(mat_path)\n",
    "\n",
    "    # Collect available channels by suffix pattern *_<CH>_time\n",
    "    series = []\n",
    "    lengths = []\n",
    "    for ch in channels:\n",
    "        # Find the key that ends with _<CH>_time, e.g., X118_DE_time\n",
    "        key = next((k for k in m.keys() if not k.startswith('__') and k.endswith(f\"_{ch}_time\")), None)\n",
    "        if key is not None:\n",
    "            arr = np.asarray(m[key]).squeeze()\n",
    "            if arr.ndim != 1:\n",
    "                arr = arr.reshape(-1)\n",
    "            series.append(arr)\n",
    "            lengths.append(arr.shape[0])\n",
    "\n",
    "    if not series:\n",
    "        raise ValueError(f\"No DE FE BA time series found in {mat_path}\")\n",
    "\n",
    "    # Use the shortest available length to align channels\n",
    "    n = min(lengths)\n",
    "    if max_len is not None:\n",
    "        n = min(n, int(max_len))\n",
    "\n",
    "    # Stack as columns in the requested channel order\n",
    "    stacked = np.stack([s[:n] for s in series], axis=1).astype(np.float32, copy=False)\n",
    "    return stacked\n",
    "\n",
    "\n",
    "\n",
    "def _resample_to_target(x_2d, up=UPSAMPLE, down=DOWNSAMPLE):\n",
    "    \"\"\"Resample along the time axis keeping channels in columns.\"\"\"\n",
    "    # x_2d shape: [time, channels]\n",
    "    y = resample_poly(x_2d, up, down, axis=0)\n",
    "    return y.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "def load_domain_data_cwru(class_labels, domain_name):\n",
    "    \"\"\"Load and resample vibration data to the target rate, using CSV cache if available.\"\"\"\n",
    "    vibration_data = {}\n",
    "\n",
    "    # Cache directory is tied to the target sampling rate\n",
    "    folder_path = f'../../data/flex-data/cwru_csv/vibration{target_sampling_rate_cwru/1000}kHz_domain{domain_name}'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    print(f\"Loading domain {domain_name} at {target_sampling_rate_cwru} Hz...\")\n",
    "\n",
    "    for label in class_labels:\n",
    "        csv_path = f'{folder_path}/{label}.csv'\n",
    "        mat_path = os.path.join(vibration_mat_folder_cwru, f\"{label}.mat\")\n",
    "\n",
    "        if os.path.exists(csv_path):\n",
    "            print(f\"  Loading {label} from resampled CSV cache...\")\n",
    "            vibration_data[label] = pd.read_csv(csv_path).values\n",
    "            continue\n",
    "\n",
    "        if os.path.exists(mat_path):\n",
    "            print(f\"  Loading {label} from .mat file and resampling...\")\n",
    "            x = _load_mat_signal(mat_path, max_len=v_length_cwru)\n",
    "            y = _resample_to_target(x, UPSAMPLE, DOWNSAMPLE)\n",
    "\n",
    "            # Optional deterministic length control from source trimming\n",
    "            # Expected resampled length based on v_length_cwru\n",
    "            expected_len = int(round(v_length_cwru * target_sampling_rate_cwru / sampling_rate_cwru))\n",
    "            if y.shape[0] != expected_len:\n",
    "                # Trim or pad to expected length if you need strict alignment across classes\n",
    "                if y.shape[0] > expected_len:\n",
    "                    y = y[:expected_len, :]\n",
    "                else:\n",
    "                    pad = np.zeros((expected_len - y.shape[0], y.shape[1]), dtype=y.dtype)\n",
    "                    y = np.vstack([y, pad])\n",
    "\n",
    "            vibration_data[label] = y\n",
    "\n",
    "            print(f\"  Saving {label} resampled CSV...\")\n",
    "            pd.DataFrame(y).to_csv(csv_path, index=False)\n",
    "        else:\n",
    "            print(f\"  Warning: {label} not found in cache or mats\")\n",
    "\n",
    "    print(f\"Domain {domain_name} loaded: {len(vibration_data)} classes at {target_sampling_rate_cwru} Hz\")\n",
    "    return vibration_data\n",
    "\n",
    "\n",
    "# Load all domains already resampled to 25.6 kHz\n",
    "vibration_data_cwru0 = load_domain_data_cwru(class_labels_cwru0, '0HP')\n",
    "vibration_data_cwru1 = load_domain_data_cwru(class_labels_cwru1, '1HP')\n",
    "vibration_data_cwru2 = load_domain_data_cwru(class_labels_cwru2, '2HP')\n",
    "\n",
    "vibration_data_cwru = {**vibration_data_cwru0, **vibration_data_cwru1, **vibration_data_cwru2}\n",
    "class_labels_cwru = list(vibration_data_cwru.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef5c761",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5189b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras >= 2.9\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# ----- helpers -----\n",
    "def crelu(x):\n",
    "    return layers.Concatenate(axis=-1)([layers.ReLU()(x), layers.ReLU()(-x)])\n",
    "\n",
    "def sep_res_block(x, filters, ksize=9, stride=1, name=\"b\"):\n",
    "    # depthwise separable conv via SeparableConv1D\n",
    "    y = layers.SeparableConv1D(filters, ksize, strides=stride, padding=\"same\", use_bias=False, name=f\"{name}_sep\")(x)\n",
    "    y = layers.BatchNormalization(name=f\"{name}_bn\")(y)\n",
    "    y = crelu(y)\n",
    "    # match shape for residual\n",
    "    if stride != 1 or x.shape[-1] != filters:\n",
    "        skip = layers.Conv1D(filters, 1, strides=stride, padding=\"same\", use_bias=False, name=f\"{name}_proj\")(x)\n",
    "        skip = layers.BatchNormalization(name=f\"{name}_proj_bn\")(skip)\n",
    "    else:\n",
    "        skip = x\n",
    "    out = layers.Add(name=f\"{name}_add\")([y, skip])\n",
    "    return out\n",
    "\n",
    "def build_model(input_length, n_channels, n_classes_main, use_aux_or_location=True, n_or_locations=3):\n",
    "    inp = layers.Input(shape=(input_length, n_channels), name=\"signal\")\n",
    "\n",
    "    # ----- stem -----\n",
    "    x = layers.Conv1D(32, 64, strides=4, padding=\"same\", use_bias=False, name=\"stem_conv\")(inp)\n",
    "    x = layers.BatchNormalization(name=\"stem_bn\")(x)\n",
    "    x = crelu(x)  # efficient first layer feature doubling\n",
    "\n",
    "    # ----- stages -----\n",
    "    x = sep_res_block(x, 64,  ksize=9, stride=2, name=\"s1_b1\")\n",
    "    x = sep_res_block(x, 64,  ksize=9, stride=1, name=\"s1_b2\")\n",
    "\n",
    "    x = sep_res_block(x, 128, ksize=9, stride=2, name=\"s2_b1\")\n",
    "    x = sep_res_block(x, 128, ksize=9, stride=1, name=\"s2_b2\")\n",
    "\n",
    "    x = sep_res_block(x, 128, ksize=9, stride=1, name=\"s3_b1\")\n",
    "    x = sep_res_block(x, 128, ksize=9, stride=1, name=\"s3_b2\")\n",
    "\n",
    "    # ----- heads -----\n",
    "    x = layers.GlobalAveragePooling1D(name=\"gap\")(x)\n",
    "    h = layers.Dense(100, activation=\"relu\", name=\"neck\")(x)\n",
    "\n",
    "    main_out = layers.Dense(n_classes_main, activation=\"softmax\", name=\"cls_main\")(h)\n",
    "\n",
    "    outputs = [main_out]\n",
    "\n",
    "    if use_aux_or_location:\n",
    "        aux_out = layers.Dense(n_or_locations, activation=\"softmax\", name=\"cls_or_loc\")(h)\n",
    "        outputs.append(aux_out)\n",
    "\n",
    "    return models.Model(inp, outputs, name=\"LDR_1D_CNN\")\n",
    "\n",
    "# ----- compile with masked auxiliary loss -----\n",
    "def compile_with_aux_mask(model, aux_weight=0.2):\n",
    "    # y_true for main is one hot. For aux, pass an extra mask channel at the end.\n",
    "    # Shape for aux y_true: [..., n_or_locations + 1], where last position is 1.0 if label present else 0.0\n",
    "    def masked_ce(y_true, y_pred):\n",
    "        y, m = y_true[..., :-1], y_true[..., -1:]\n",
    "        ce = tf.keras.losses.categorical_crossentropy(y, y_pred)\n",
    "        ce = ce * tf.squeeze(m, axis=-1)\n",
    "        denom = tf.maximum(tf.reduce_mean(m), 1e-6)\n",
    "        return tf.reduce_sum(ce) / denom\n",
    "\n",
    "    losses = {\"cls_main\": \"categorical_crossentropy\"}\n",
    "    loss_weights = {\"cls_main\": 1.0}\n",
    "\n",
    "    if \"cls_or_loc\" in [o.name for o in model.outputs]:\n",
    "        losses[\"cls_or_loc\"] = masked_ce\n",
    "        loss_weights[\"cls_or_loc\"] = aux_weight\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=losses, loss_weights=loss_weights,\n",
    "                  metrics={\"cls_main\": [\"accuracy\"]})\n",
    "    return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
