{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9e5a519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../data/vibrationCWRU/OR007@12_0.csv',\n",
       " '../../data/vibrationCWRU/OR007@12_0.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python 3.x\n",
    "# pip install scipy numpy pandas\n",
    "import json\n",
    "import re\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from fractions import Fraction\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import resample_poly\n",
    "\n",
    "# ------- config -------\n",
    "TARGET_FS = 25600  # Hz to match KAIST\n",
    "OUT_DIR = pathlib.Path(\"../../data/vibrationCWRU\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Helpers to find time-domain arrays in CWRU .mat\n",
    "CWRU_KEY_ORDER = [\n",
    "    # common CWRU naming patterns\n",
    "    r\".*_DE_time$\",   # drive end accel\n",
    "    r\".*_FE_time$\",   # fan end accel\n",
    "    r\".*_BA_time$\",   # base accel\n",
    "    r\".*_AE_time$\",   # acoustic emission if present\n",
    "    r\".*DE$\", r\".*FE$\", r\".*BA$\",\n",
    "]\n",
    "\n",
    "def _flatten_1d(x):\n",
    "    x = np.asarray(x)\n",
    "    if x.ndim == 2 and 1 in x.shape:\n",
    "        x = x.reshape(-1)\n",
    "    return x.squeeze()\n",
    "\n",
    "def _extract_channels(matdict):\n",
    "    # collect all 1D numeric arrays\n",
    "    candidates = {}\n",
    "    for k, v in matdict.items():\n",
    "        if k.startswith(\"__\"):\n",
    "            continue\n",
    "        try:\n",
    "            arr = _flatten_1d(v)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if np.issubdtype(arr.dtype, np.number) and arr.ndim == 1 and arr.size > 10:\n",
    "            candidates[k] = arr\n",
    "\n",
    "    # order channels by regex priority\n",
    "    ordered = []\n",
    "    used = set()\n",
    "    for pat in CWRU_KEY_ORDER:\n",
    "        rx = re.compile(pat, re.IGNORECASE)\n",
    "        for k in list(candidates.keys()):\n",
    "            if k in used:\n",
    "                continue\n",
    "            if rx.match(k):\n",
    "                ordered.append(candidates[k])\n",
    "                used.add(k)\n",
    "    # add any leftover numeric vectors\n",
    "    for k, arr in candidates.items():\n",
    "        if k not in used:\n",
    "            ordered.append(arr)\n",
    "\n",
    "    return ordered[:4]  # up to four channels\n",
    "\n",
    "def _infer_fs_from_mat(matdict, default_fs=12000):\n",
    "    # try common field names\n",
    "    for k in matdict.keys():\n",
    "        if \"fs\" == k.lower() or \"samplingrate\" in k.lower():\n",
    "            fs_val = np.asarray(matdict[k]).astype(float).squeeze()\n",
    "            if fs_val.size >= 1:\n",
    "                return float(fs_val.flat[0])\n",
    "    # try to guess from CWRU naming like X097_DE_time -> 12 kHz or 48 kHz are common\n",
    "    return float(default_fs)\n",
    "\n",
    "def _stack_to_four(chans):\n",
    "    \"\"\"stack list of 1D arrays to shape [N,4], padding with zeros if fewer than 4.\"\"\"\n",
    "    maxlen = min([len(c) for c in chans]) if len(chans) > 0 else 0\n",
    "    if len(chans) == 0 or maxlen == 0:\n",
    "        return np.zeros((0, 4), dtype=np.float32)\n",
    "    # align to shortest to keep synchronous\n",
    "    chans = [c[:maxlen] for c in chans]\n",
    "    X = np.zeros((maxlen, 4), dtype=np.float32)\n",
    "    for i, c in enumerate(chans[:4]):\n",
    "        X[:, i] = c.astype(np.float32)\n",
    "    return X\n",
    "\n",
    "def _resample_if_needed(X, fs_in, fs_out):\n",
    "    fs_in = int(round(float(fs_in)))\n",
    "    fs_out = int(round(float(fs_out)))\n",
    "    if X.size == 0 or fs_in == fs_out:\n",
    "        return X\n",
    "    frac = Fraction(fs_out, fs_in)  # now both ints\n",
    "    up, down = frac.numerator, frac.denominator\n",
    "    Y = resample_poly(X, up, down, axis=0)\n",
    "    return Y.astype(np.float32)\n",
    "\n",
    "def convert_mat_to_csv(mat_path, label=\"Normal\", load_nm=None, dataset_id=\"cwru\",\n",
    "                       or_loc=None, out_dir=OUT_DIR):\n",
    "    mat_path = pathlib.Path(mat_path)\n",
    "    md = loadmat(mat_path.as_posix(), squeeze_me=False, struct_as_record=False)\n",
    "\n",
    "    chans = _extract_channels(md)\n",
    "    fs_in = _infer_fs_from_mat(md, default_fs=12000.0)\n",
    "    X = _stack_to_four(chans)\n",
    "    X = _resample_if_needed(X, fs_in, TARGET_FS)\n",
    "\n",
    "    # write CSV with no header, four columns: sensor1..sensor4\n",
    "    csv_name = mat_path.stem + \".csv\"\n",
    "    csv_path = out_dir / csv_name\n",
    "    np.savetxt(csv_path.as_posix(), X, delimiter=\",\", fmt=\"%.7f\")\n",
    "\n",
    "    # write sidecar metadata\n",
    "    meta = {\n",
    "        \"source_file\": mat_path.name,\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"label\": label,                 # e.g., normal, inner_race, ball, outer_race\n",
    "        \"outer_race_location\": or_loc,  # e.g., \"3\", \"6\", \"12\" oclock if known\n",
    "        \"load_Nm\": load_nm,             # if known\n",
    "        \"sampling_rate_hz\": TARGET_FS,\n",
    "        \"channels\": [\"sensor1\", \"sensor2\", \"sensor3\", \"sensor4\"],\n",
    "        \"notes\": \"headerless CSV for CNN. Values are vibration samples. Missing channels are zero padded.\",\n",
    "    }\n",
    "    json_path = out_dir / (mat_path.stem + \".json\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    return csv_path.as_posix(), json_path.as_posix()\n",
    "\n",
    "# Example\n",
    "# convert_mat_to_csv(\"./Normal_0.mat\", label=\"normal\", load_nm=0, dataset_id=\"cwru\")\n",
    "convert_mat_to_csv(\"../../data/raw_cwru/vibration_mat/IR007_0.mat\", label=\"inner_race\", load_nm=0, dataset_id=\"cwru\")\n",
    "convert_mat_to_csv(\"../../data/raw_cwru/vibration_mat/B007_0.mat\", label=\"inner_race\", load_nm=0, dataset_id=\"cwru\")\n",
    "convert_mat_to_csv(\"../../data/raw_cwru/vibration_mat/Normal_0.mat\", label=\"inner_race\", load_nm=0, dataset_id=\"cwru\")\n",
    "convert_mat_to_csv(\"../../data/raw_cwru/vibration_mat/OR007@3_0.mat\", label=\"inner_race\", load_nm=0, dataset_id=\"cwru\")\n",
    "convert_mat_to_csv(\"../../data/raw_cwru/vibration_mat/OR007@6_0.mat\", label=\"inner_race\", load_nm=0, dataset_id=\"cwru\")\n",
    "convert_mat_to_csv(\"../../data/raw_cwru/vibration_mat/OR007@12_0.mat\", label=\"inner_race\", load_nm=0, dataset_id=\"cwru\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e580a",
   "metadata": {},
   "source": [
    "Join JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f3c3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged 7 JSON files into ..\\..\\data\\vibrationCWRU\\cwru_metadata.json and deleted originals.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('../../data/vibrationCWRU/cwru_metadata.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "def join_jsons(folder, out_file=\"merged.json\"):\n",
    "    folder = pathlib.Path(folder)\n",
    "    json_files = sorted(folder.glob(\"*.json\"))\n",
    "\n",
    "    all_data = []\n",
    "    for jf in json_files:\n",
    "        try:\n",
    "            with open(jf, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "                # keep track of original file\n",
    "                if isinstance(data, dict):\n",
    "                    data[\"_source_file\"] = jf.name\n",
    "                all_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping {jf}: {e}\")\n",
    "\n",
    "    out_path = folder / out_file\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_data, f, indent=2)\n",
    "\n",
    "    # delete original JSON files except the merged one\n",
    "    for jf in json_files:\n",
    "        try:\n",
    "            if jf.name != out_file:\n",
    "                jf.unlink()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not delete {jf}: {e}\")\n",
    "\n",
    "    print(f\"✅ Merged {len(all_data)} JSON files into {out_path} and deleted originals.\")\n",
    "    return out_path\n",
    "\n",
    "# Merge all JSONs in ./out_csv into merged.json\n",
    "join_jsons(OUT_DIR, out_file=\"cwru_metadata.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
